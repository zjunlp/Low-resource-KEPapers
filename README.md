# Low-resource Knowledge Extraction 

The repository is a paper set on low-resource knowledge extraction (NER, RE, EE), which is categorized into three paradigms. 

## Content
* [1 Exploiting Higher-resource Data](#1-Exploiting-Higher-resource-Data)
  * [1.1 Weakly Supervised Augmentation](#Weakly-Supervised-Augmentation)
  * [1.2 Multi-modal Augmentation](#Multi-modal-Augmentation)
  * [1.3 Multi-lingual Augmentation](#Multi-lingual-Augmentation)
  * [1.4 Auxiliary Knowledge Enhancement](#Auxiliary-Knowledge-Enhancement)
* [2 Exploiting Stronger Models](#2-Exploiting-Stronger-Models)
  * [2.1 Meta Learning](#Meta-Learning)
  * [2.2 Transfer Learning](#Transfer-Learning)
  * [2.3 Prompt Learning](#Prompt-Learning)
* [Exploiting Data and Models Together](#Exploiting-Data-and-Models-Together)
  * [3.1 Multi-task Learning](#Multi-task-Learning)
  * [3.2 Formulating KE as QA/MRC](#Formulating-KE-as-QA-and-MRC)
  * [3.3 Retrieval Augmentation](#Retrieval-Augmentation)

## 1 Exploiting Higher-resource Data

* () [[paper]]()
* () [[paper]]()
* () [[paper]]()
* () [[paper]]()


### Weakly Supervised Augmentation

* Distant supervision for relation extraction without labeled data (ACL 2009) [[paper]](https://dl.acm.org/doi/pdf/10.5555/1690219.1690287)
* BOND: BERT-Assisted Open-Domain Named Entity Recognition with Distant Supervision () [[paper]](https://dl.acm.org/doi/abs/10.1145/3394486.3403149)
* () [[paper]]()
* () [[paper]]()


### Multi-modal Augmentation
* []()
* []()
* []()
* []()
* []()
* []()
* []()
* []()
* []()
* []()
* []()


### Multi-lingual Augmentation
* []()
* []()
* []()
* []()
* []()
* []()
* []()
* []()
* []()
* []()
* []()


### Auxiliary Knowledge Enhancement
#### Text
* []()
* []()
* []()
* []()
* []()

#### KG
* []()
* []()
* []()
* []()
* []()

#### Ontology & Rule
* []()
* []()
* []()
* []()
* []()


## 2 Exploiting Stronger Models

### Meta Learning

#### For Low-resource NER
* []()
* []()
* []()
* []()
* []()

#### For Low-resource RE
* []()
* []()
* []()
* []()
* []()

#### For Low-resource EE
* []()
* []()
* []()
* []()
* []()

### Transfer Learning

#### Class-related Semantics
* []()
* []()
* []()
* []()
* []()

#### Pre-trained Language Representations
* []()
* []()
* []()
* []()
* []()


### Prompt Learning

#### Vanilla Prompt Learning
* []()
* []()
* []()
* []()
* []()

#### Augmented Prompt Learning
* []()
* []()
* []()
* []()
* []()


## 3 Exploiting Data and Models Together

### Multi-task Learning

#### NER, named entity normalization
* []()
* []()
* []()
* []()
* []()

#### NER, RE
* []()
* []()
* []()
* []()
* []()

#### NER, RE, EE
* []()
* []()
* []()
* []()
* []()

#### word sense disambiguation (WSD), event detection (ED)
* []()
* []()
* []()
* []()
* []()

### Formulating KE as QA and MRC
* []()
* []()
* []()
* []()
* []()
* []()
* []()
* []()
* []()
* []()

### Retrieval Augmentation

#### Retrieval-based Language Models
* []()
* []()
* []()
* []()
* []()

#### Few-shot Settings
* []()
* []()
* []()
* []()
* []()
